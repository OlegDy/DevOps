module.instance["prod"].data.yandex_compute_image.image: Reading...
module.instance["node"].data.yandex_compute_image.image: Reading...
module.instance["prod"].data.yandex_compute_image.image: Read complete after 1s [id=fd8jvcoeij6u9se84dt5]
module.instance["node"].data.yandex_compute_image.image: Read complete after 1s [id=fd8jvcoeij6u9se84dt5]

Terraform used the selected providers to generate the following execution
plan. Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  # yandex_vpc_network.default will be created
  + resource "yandex_vpc_network" "default" {
      + created_at                = (known after apply)
      + default_security_group_id = (known after apply)
      + folder_id                 = (known after apply)
      + id                        = (known after apply)
      + name                      = "net"
      + subnet_ids                = (known after apply)
    }

  # yandex_vpc_subnet.default will be created
  + resource "yandex_vpc_subnet" "default" {
      + created_at     = (known after apply)
      + folder_id      = (known after apply)
      + id             = (known after apply)
      + name           = "subnet"
      + network_id     = (known after apply)
      + v4_cidr_blocks = [
          + "192.168.101.0/24",
        ]
      + v6_cidr_blocks = (known after apply)
      + zone           = "ru-central1-a"
    }

  # module.instance["node"].yandex_compute_instance.instance[0] will be created
  + resource "yandex_compute_instance" "instance" {
      + created_at                = (known after apply)
      + description               = "Modules test"
      + folder_id                 = "b1gft0uc6bptguk1tekv"
      + fqdn                      = (known after apply)
      + hostname                  = "node-1"
      + id                        = (known after apply)
      + metadata                  = {
          + "ssh-keys" = <<-EOT
                centos:ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCo+48Wll4DoPRqXqJLawYCO7lKqcNa7dIHzSCmCv+PG3ICSuzaJREI09903zlmBboQ9V5gO4zS8KT5SvtrWvQAk3+IPDow8YY0s13OcTSjUpHDbYHV+KnBZWT2Rvv8j/nd+wsK/vN6Czw1EPeQ+a4e7coTwbovnBG06uCk6T1zS9rYCXdZd7ykGCZs7fxsrlKYORXC7EUTCEblGy7ybVXCy6H6GTI4wipuLdqDCjE8ELbn2iQiewjQCFXNzjt/3lFxav/Zf8emCc1hhuKpTMt+ltCFJIQw7IcyB1ZKkEFC4AUt90CNnNaqDulkJtg5gnGfWKZ5L/6kLUtRM9L1fhxlmB5+kAplmIGrIxO7PYYxk4QOH6iCb85NQlgNZ8/otnJGQkrs37s3Gf7r95NRV+1sjNdndyPoHEZgbgXhOZl1CSguMofjDRqnfG0BBVqTSM3a88STC+9vAL1Jso2LlsOB4SxOn9VfX4DmOfibi1TKb9QkeDNVjMLBCwyYOGLpTE0= root@server1
            EOT
        }
      + name                      = "node-1"
      + network_acceleration_type = "standard"
      + platform_id               = "standard-v2"
      + service_account_id        = (known after apply)
      + status                    = (known after apply)
      + zone                      = "ru-central1-a"

      + boot_disk {
          + auto_delete = true
          + device_name = (known after apply)
          + disk_id     = (known after apply)
          + mode        = (known after apply)

          + initialize_params {
              + description = (known after apply)
              + image_id    = "fd8jvcoeij6u9se84dt5"
              + name        = (known after apply)
              + size        = 40
              + snapshot_id = (known after apply)
              + type        = "network-ssd"
            }
        }

      + network_interface {
          + index              = (known after apply)
          + ip_address         = (known after apply)
          + ipv4               = true
          + ipv6               = (known after apply)
          + ipv6_address       = (known after apply)
          + mac_address        = (known after apply)
          + nat                = true
          + nat_ip_address     = (known after apply)
          + nat_ip_version     = (known after apply)
          + security_group_ids = (known after apply)
          + subnet_id          = (known after apply)
        }

      + placement_policy {
          + placement_group_id = (known after apply)
        }

      + resources {
          + core_fraction = 100
          + cores         = 4
          + memory        = 8
        }

      + scheduling_policy {
          + preemptible = (known after apply)
        }
    }

  # module.instance["node"].yandex_compute_instance.instance[1] will be created
  + resource "yandex_compute_instance" "instance" {
      + created_at                = (known after apply)
      + description               = "Modules test"
      + folder_id                 = "b1gft0uc6bptguk1tekv"
      + fqdn                      = (known after apply)
      + hostname                  = "node-2"
      + id                        = (known after apply)
      + metadata                  = {
          + "ssh-keys" = <<-EOT
                centos:ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCo+48Wll4DoPRqXqJLawYCO7lKqcNa7dIHzSCmCv+PG3ICSuzaJREI09903zlmBboQ9V5gO4zS8KT5SvtrWvQAk3+IPDow8YY0s13OcTSjUpHDbYHV+KnBZWT2Rvv8j/nd+wsK/vN6Czw1EPeQ+a4e7coTwbovnBG06uCk6T1zS9rYCXdZd7ykGCZs7fxsrlKYORXC7EUTCEblGy7ybVXCy6H6GTI4wipuLdqDCjE8ELbn2iQiewjQCFXNzjt/3lFxav/Zf8emCc1hhuKpTMt+ltCFJIQw7IcyB1ZKkEFC4AUt90CNnNaqDulkJtg5gnGfWKZ5L/6kLUtRM9L1fhxlmB5+kAplmIGrIxO7PYYxk4QOH6iCb85NQlgNZ8/otnJGQkrs37s3Gf7r95NRV+1sjNdndyPoHEZgbgXhOZl1CSguMofjDRqnfG0BBVqTSM3a88STC+9vAL1Jso2LlsOB4SxOn9VfX4DmOfibi1TKb9QkeDNVjMLBCwyYOGLpTE0= root@server1
            EOT
        }
      + name                      = "node-2"
      + network_acceleration_type = "standard"
      + platform_id               = "standard-v2"
      + service_account_id        = (known after apply)
      + status                    = (known after apply)
      + zone                      = "ru-central1-a"

      + boot_disk {
          + auto_delete = true
          + device_name = (known after apply)
          + disk_id     = (known after apply)
          + mode        = (known after apply)

          + initialize_params {
              + description = (known after apply)
              + image_id    = "fd8jvcoeij6u9se84dt5"
              + name        = (known after apply)
              + size        = 40
              + snapshot_id = (known after apply)
              + type        = "network-ssd"
            }
        }

      + network_interface {
          + index              = (known after apply)
          + ip_address         = (known after apply)
          + ipv4               = true
          + ipv6               = (known after apply)
          + ipv6_address       = (known after apply)
          + mac_address        = (known after apply)
          + nat                = true
          + nat_ip_address     = (known after apply)
          + nat_ip_version     = (known after apply)
          + security_group_ids = (known after apply)
          + subnet_id          = (known after apply)
        }

      + placement_policy {
          + placement_group_id = (known after apply)
        }

      + resources {
          + core_fraction = 100
          + cores         = 4
          + memory        = 8
        }

      + scheduling_policy {
          + preemptible = (known after apply)
        }
    }

  # module.instance["prod"].yandex_compute_instance.instance[0] will be created
  + resource "yandex_compute_instance" "instance" {
      + created_at                = (known after apply)
      + description               = "Modules test"
      + folder_id                 = "b1gft0uc6bptguk1tekv"
      + fqdn                      = (known after apply)
      + hostname                  = "prod-1"
      + id                        = (known after apply)
      + metadata                  = {
          + "ssh-keys" = <<-EOT
                centos:ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCo+48Wll4DoPRqXqJLawYCO7lKqcNa7dIHzSCmCv+PG3ICSuzaJREI09903zlmBboQ9V5gO4zS8KT5SvtrWvQAk3+IPDow8YY0s13OcTSjUpHDbYHV+KnBZWT2Rvv8j/nd+wsK/vN6Czw1EPeQ+a4e7coTwbovnBG06uCk6T1zS9rYCXdZd7ykGCZs7fxsrlKYORXC7EUTCEblGy7ybVXCy6H6GTI4wipuLdqDCjE8ELbn2iQiewjQCFXNzjt/3lFxav/Zf8emCc1hhuKpTMt+ltCFJIQw7IcyB1ZKkEFC4AUt90CNnNaqDulkJtg5gnGfWKZ5L/6kLUtRM9L1fhxlmB5+kAplmIGrIxO7PYYxk4QOH6iCb85NQlgNZ8/otnJGQkrs37s3Gf7r95NRV+1sjNdndyPoHEZgbgXhOZl1CSguMofjDRqnfG0BBVqTSM3a88STC+9vAL1Jso2LlsOB4SxOn9VfX4DmOfibi1TKb9QkeDNVjMLBCwyYOGLpTE0= root@server1
            EOT
        }
      + name                      = "prod-1"
      + network_acceleration_type = "standard"
      + platform_id               = "standard-v2"
      + service_account_id        = (known after apply)
      + status                    = (known after apply)
      + zone                      = "ru-central1-a"

      + boot_disk {
          + auto_delete = true
          + device_name = (known after apply)
          + disk_id     = (known after apply)
          + mode        = (known after apply)

          + initialize_params {
              + description = (known after apply)
              + image_id    = "fd8jvcoeij6u9se84dt5"
              + name        = (known after apply)
              + size        = 40
              + snapshot_id = (known after apply)
              + type        = "network-ssd"
            }
        }

      + network_interface {
          + index              = (known after apply)
          + ip_address         = (known after apply)
          + ipv4               = true
          + ipv6               = (known after apply)
          + ipv6_address       = (known after apply)
          + mac_address        = (known after apply)
          + nat                = true
          + nat_ip_address     = (known after apply)
          + nat_ip_version     = (known after apply)
          + security_group_ids = (known after apply)
          + subnet_id          = (known after apply)
        }

      + placement_policy {
          + placement_group_id = (known after apply)
        }

      + resources {
          + core_fraction = 100
          + cores         = 4
          + memory        = 8
        }

      + scheduling_policy {
          + preemptible = (known after apply)
        }
    }

  # module.instance["prod"].yandex_compute_instance.instance[1] will be created
  + resource "yandex_compute_instance" "instance" {
      + created_at                = (known after apply)
      + description               = "Modules test"
      + folder_id                 = "b1gft0uc6bptguk1tekv"
      + fqdn                      = (known after apply)
      + hostname                  = "prod-2"
      + id                        = (known after apply)
      + metadata                  = {
          + "ssh-keys" = <<-EOT
                centos:ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCo+48Wll4DoPRqXqJLawYCO7lKqcNa7dIHzSCmCv+PG3ICSuzaJREI09903zlmBboQ9V5gO4zS8KT5SvtrWvQAk3+IPDow8YY0s13OcTSjUpHDbYHV+KnBZWT2Rvv8j/nd+wsK/vN6Czw1EPeQ+a4e7coTwbovnBG06uCk6T1zS9rYCXdZd7ykGCZs7fxsrlKYORXC7EUTCEblGy7ybVXCy6H6GTI4wipuLdqDCjE8ELbn2iQiewjQCFXNzjt/3lFxav/Zf8emCc1hhuKpTMt+ltCFJIQw7IcyB1ZKkEFC4AUt90CNnNaqDulkJtg5gnGfWKZ5L/6kLUtRM9L1fhxlmB5+kAplmIGrIxO7PYYxk4QOH6iCb85NQlgNZ8/otnJGQkrs37s3Gf7r95NRV+1sjNdndyPoHEZgbgXhOZl1CSguMofjDRqnfG0BBVqTSM3a88STC+9vAL1Jso2LlsOB4SxOn9VfX4DmOfibi1TKb9QkeDNVjMLBCwyYOGLpTE0= root@server1
            EOT
        }
      + name                      = "prod-2"
      + network_acceleration_type = "standard"
      + platform_id               = "standard-v2"
      + service_account_id        = (known after apply)
      + status                    = (known after apply)
      + zone                      = "ru-central1-a"

      + boot_disk {
          + auto_delete = true
          + device_name = (known after apply)
          + disk_id     = (known after apply)
          + mode        = (known after apply)

          + initialize_params {
              + description = (known after apply)
              + image_id    = "fd8jvcoeij6u9se84dt5"
              + name        = (known after apply)
              + size        = 40
              + snapshot_id = (known after apply)
              + type        = "network-ssd"
            }
        }

      + network_interface {
          + index              = (known after apply)
          + ip_address         = (known after apply)
          + ipv4               = true
          + ipv6               = (known after apply)
          + ipv6_address       = (known after apply)
          + mac_address        = (known after apply)
          + nat                = true
          + nat_ip_address     = (known after apply)
          + nat_ip_version     = (known after apply)
          + security_group_ids = (known after apply)
          + subnet_id          = (known after apply)
        }

      + placement_policy {
          + placement_group_id = (known after apply)
        }

      + resources {
          + core_fraction = 100
          + cores         = 4
          + memory        = 8
        }

      + scheduling_policy {
          + preemptible = (known after apply)
        }
    }

Plan: 6 to add, 0 to change, 0 to destroy.

Changes to Outputs:
  + public_ip = {
      + node = [
          + (known after apply),
          + (known after apply),
        ]
      + prod = [
          + (known after apply),
          + (known after apply),
        ]
    }

─────────────────────────────────────────────────────────────────────────────

Note: You didn't use the -out option to save this plan, so Terraform can't
guarantee to take exactly these actions if you run "terraform apply" now.
